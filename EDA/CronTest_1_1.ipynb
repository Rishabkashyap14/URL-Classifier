{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import whois\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib3\n",
    "urllib3.disable_warnings()\n",
    "from urllib3 import request\n",
    "from csv import writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_registered(domain_name):\n",
    "    \"\"\"A function that returns a boolean indicating whether a `domain_name` is registered\"\"\"\n",
    "    try:\n",
    "        w = whois.whois(domain_name)\n",
    "    except Exception:\n",
    "        return False\n",
    "    else:\n",
    "        return w.domain_name, w.creation_date, w.expiration_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['UNISWAPWEB-RESTORE.COM', 'uniswapweb-restore.com'], datetime.datetime(2021, 5, 15, 14, 47, 23), datetime.datetime(2022, 5, 15, 14, 47, 23))\n",
      "(['PAXFUL-CLAIM.COM', 'paxful-claim.com'], datetime.datetime(2021, 4, 27, 6, 51, 20), datetime.datetime(2022, 4, 27, 6, 51, 20))\n",
      "(['mypay.pictures', 'MYPAY.PICTURES'], datetime.datetime(2021, 5, 15, 12, 23, 59), datetime.datetime(2022, 5, 15, 12, 23, 59))\n",
      "('goodseo.tw', datetime.datetime(2017, 2, 2, 21, 5, 19), datetime.datetime(2024, 2, 2, 21, 5, 19))\n",
      "(['JIMDOFREE.COM', 'jimdofree.com'], datetime.datetime(2018, 3, 5, 13, 21, 6), datetime.datetime(2022, 3, 5, 13, 21, 6))\n",
      "(['MELANDDAKK.COM', 'melanddakk.com'], [datetime.datetime(2021, 5, 13, 13, 3, 13), datetime.datetime(2021, 5, 13, 8, 3, 13)], [datetime.datetime(2022, 5, 13, 13, 3, 13), datetime.datetime(2022, 5, 13, 8, 3, 13)])\n",
      "('ATAGUCSEA.COM', datetime.datetime(2014, 10, 2, 12, 54, 52), datetime.datetime(2021, 10, 2, 12, 54, 52))\n",
      "(['WBSTORMER.COM', 'wbstormer.com'], datetime.datetime(2018, 1, 24, 22, 8, 33), datetime.datetime(2022, 1, 24, 22, 8, 33))\n",
      "(['LOOKATMYNEWPHOTOS.COM', 'lookatmynewphotos.com'], datetime.datetime(2017, 7, 4, 2, 23, 55), datetime.datetime(2022, 7, 4, 2, 23, 55))\n",
      "('polymercenter.com.ua', [datetime.datetime(2014, 2, 12, 16, 28, 18), datetime.datetime(2013, 4, 8, 22, 19, 45)], datetime.datetime(2022, 2, 12, 16, 28, 18))\n",
      "('LIVRAISONCLIENT.COM', datetime.datetime(2020, 7, 6, 16, 14, 48), datetime.datetime(2021, 7, 6, 16, 14, 48))\n",
      "('aabuqnduqun.top', datetime.datetime(2020, 7, 17, 13, 51, 31), datetime.datetime(2021, 7, 17, 13, 51, 31))\n",
      "(['WUAMERIGO.COM', 'wuamerigo.com'], datetime.datetime(2016, 11, 28, 9, 39, 20), datetime.datetime(2021, 11, 28, 9, 39, 20))\n",
      "('USAHAWAN.CC', [datetime.datetime(2012, 10, 23, 10, 37, 26), datetime.datetime(2012, 10, 23, 5, 37, 26)], [datetime.datetime(2023, 10, 23, 10, 37, 26), datetime.datetime(2023, 10, 23, 5, 37, 26)])\n",
      "Error trying to connect to socket: closing socket\n"
     ]
    }
   ],
   "source": [
    "openPhishURL=\"https://www.openphish.com/\"\n",
    "openPhishSoup = BeautifulSoup(requests.get(openPhishURL).content,'html.parser')\n",
    "df = pd.read_csv(\"data.csv\", index_col=0)\n",
    "count2= len(df['URL'])\n",
    "for tr in openPhishSoup.findAll('td',class_= \"url_entry\"):\n",
    "  url = tr.text\n",
    "  if(url not in list(df['URL'])):\n",
    "    w = is_registered(url)\n",
    "    if (w and w[0]!=None):\n",
    "      try :\n",
    "        page = requests.get(url, verify=False, timeout=15)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        if (page and page.status_code == 200 and soup):\n",
    "          print(w)\n",
    "          df.loc[count2, 'URL'] = url\n",
    "          fileName = \"f\"+str (count2)+'.html'\n",
    "          df.loc[count2, 'Filename'] = fileName\n",
    "          my_data_file = open(fileName, 'w')\n",
    "          my_data_file.writelines(\"<!-- URL =\"+url+\"-->\")\n",
    "          my_data_file.writelines(\"<!-- w =\"+str (w)+\"-->\")\n",
    "          my_data_file.writelines(str (soup.prettify()))\n",
    "          my_data_file.close()\n",
    "          count2+=1\n",
    "      except requests.exceptions.RequestException:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
